{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f46e44-95aa-4abf-a3ea-3ded816f0ee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aperçu du dataset :\n",
      "   a_etage  cheminee classification_f  cuve_eau  douche_wc etat_general  \\\n",
      "0    False      True               F6     False  interieur          bon   \n",
      "1    False     False               F5     False  interieur          bon   \n",
      "2    False     False               F4     False  interieur          bon   \n",
      "3    False     False               F6     False  interieur          bon   \n",
      "4    False     False               F6     False  interieur          bon   \n",
      "\n",
      "   garage_ferme  gardien_securite  groupe_electrogene  loyer_mensuel  ...  \\\n",
      "0         False             False               False      4000000.0  ...   \n",
      "1         False              True               False      9000000.0  ...   \n",
      "2         False             False               False      1700000.0  ...   \n",
      "3         False             False               False      8500000.0  ...   \n",
      "4         False             False               False      8500000.0  ...   \n",
      "\n",
      "   nombre_salles_eau  piscine                   quartier  superficie  \\\n",
      "0                2.0    False                    ivandry         0.0   \n",
      "1                2.0     True  ambohimanambola firaisana         0.0   \n",
      "2                2.0    False  ambohimanambola firaisana         0.0   \n",
      "3                2.0    False                   ambatobe         0.0   \n",
      "4                2.0    False                   ambatobe         0.0   \n",
      "\n",
      "  surface_terrain  terrasse_balcon          type_d_acces  type_logement  \\\n",
      "0           600.0             True  voiture_avec_parking          Villa   \n",
      "1             0.0             True  voiture_avec_parking          Villa   \n",
      "2             0.0             True  voiture_avec_parking          Villa   \n",
      "3             0.0            False  voiture_avec_parking          Villa   \n",
      "4             0.0            False  voiture_avec_parking          Villa   \n",
      "\n",
      "                nom_quartier id_quartier  \n",
      "0                    ivandry       139.0  \n",
      "1  ambohimanambola firaisana       237.0  \n",
      "2  ambohimanambola firaisana       237.0  \n",
      "3                   ambatobe       143.0  \n",
      "4                   ambatobe       499.0  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "Valeurs manquantes par colonne :\n",
      "a_etage                 0\n",
      "cheminee                0\n",
      "classification_f        0\n",
      "cuve_eau                0\n",
      "douche_wc               0\n",
      "etat_general            0\n",
      "garage_ferme            0\n",
      "gardien_securite        0\n",
      "groupe_electrogene      0\n",
      "loyer_mensuel           0\n",
      "meuble                  0\n",
      "nombre_chambres         0\n",
      "nombre_salles_eau       0\n",
      "piscine                 0\n",
      "quartier                0\n",
      "superficie              0\n",
      "surface_terrain         0\n",
      "terrasse_balcon         0\n",
      "type_d_acces            0\n",
      "type_logement           0\n",
      "nom_quartier          212\n",
      "id_quartier           212\n",
      "dtype: int64\n",
      "\n",
      "✅ Prétraitement terminé. Dimensions de X prétraité : (2407, 239)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "df = pd.read_csv(\"logement_tana_avec_idquartier.csv\")\n",
    "\n",
    "print(\"Aperçu du dataset :\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nValeurs manquantes par colonne :\")\n",
    "print(df.isnull().sum())\n",
    "num_cols = ['superficie', 'surface_terrain', 'nombre_chambres', 'nombre_salles_eau'] \n",
    "cat_cols = ['quartier', 'douche_wc', 'etat_general', 'type_d_acces', 'type_logement', 'meuble'] \n",
    "\n",
    "target_col = 'loyer_mensuel' \n",
    "\n",
    "num_imputer = SimpleImputer(strategy='median')\n",
    "cat_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', Pipeline([\n",
    "        ('imputer', num_imputer),\n",
    "        ('scaler', StandardScaler())\n",
    "    ]), num_cols),\n",
    "\n",
    "    ('cat', Pipeline([\n",
    "        ('imputer', cat_imputer),\n",
    "        ('encoder', encoder)\n",
    "    ]), cat_cols)\n",
    "])\n",
    "\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "X_preprocessed = preprocessor.fit_transform(X)\n",
    "\n",
    "print(\"\\n✅ Prétraitement terminé. Dimensions de X prétraité :\", X_preprocessed.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb29f70",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5ab470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " R² test final : 0.7284\n",
      " RMSE test final : 1724018.21\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=RuntimeWarning)\n",
    "\n",
    "df = pd.read_csv(\"logement_cleaned.csv\")\n",
    "\n",
    "# Convertir les colonnes booléennes en int\n",
    "bool_cols = [col for col in df.columns if df[col].dtype == \"bool\"]\n",
    "for col in bool_cols:\n",
    "    df[col] = df[col].astype(int)\n",
    "\n",
    "# Définir les colonnes numériques et catégorielles\n",
    "num_cols = [\"superficie\", \"surface_terrain\", \"nombre_chambres\", \"nombre_salles_eau\"] + bool_cols\n",
    "cat_cols = [\"quartier\", \"douche_wc\", \"etat_general\", \"type_d_acces\", \"type_logement\"]\n",
    "\n",
    "X = df.drop(columns=[\"loyer_mensuel\"])\n",
    "y = df[\"loyer_mensuel\"]\n",
    "\n",
    "# Filtrage par variance\n",
    "X_num = X[num_cols].copy()\n",
    "imputer_num = SimpleImputer(strategy=\"median\")\n",
    "X_num_imputed = pd.DataFrame(imputer_num.fit_transform(X_num), columns=num_cols)\n",
    "\n",
    "selector_var = VarianceThreshold(threshold=1e-5)\n",
    "selector_var.fit(X_num_imputed)\n",
    "cols_var = X_num_imputed.columns[selector_var.get_support()].tolist()\n",
    "\n",
    "num_cols_filtered = cols_var\n",
    "\n",
    "# Séparation en train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Pipelines pour les colonnes numériques et catégorielles\n",
    "num_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "cat_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", num_transformer, num_cols_filtered),\n",
    "    (\"cat\", cat_transformer, cat_cols)\n",
    "])\n",
    "\n",
    "# Pipeline complet\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocess\", preprocessor),\n",
    "    (\"select\", SelectKBest(score_func=f_regression)),\n",
    "    (\"regressor\", Ridge())\n",
    "])\n",
    "\n",
    "# Grille des hyperparamètres\n",
    "param_grid = {\n",
    "    \"select__k\": [10, 20, 30, 40, 50],\n",
    "    \"regressor__alpha\": [0.1, 1.0, 10.0, 100.0]\n",
    "}\n",
    "\n",
    "# GridSearch sans verbose\n",
    "grid_search = GridSearchCV(\n",
    "    pipeline,\n",
    "    param_grid,\n",
    "    scoring=\"r2\",\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Entraînement\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Prédiction et évaluation\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "print(f\" R² test final : {r2:.4f}\")\n",
    "print(f\" RMSE test final : {rmse:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c988b5c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51509302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Suppression variable idx=4 avec p-value=0.9911521483560483\n",
      "Suppression variable idx=16 avec p-value=0.962720231695096\n",
      "Suppression variable idx=6 avec p-value=0.9419752341254297\n",
      "Suppression variable idx=30 avec p-value=0.941842603052384\n",
      "Suppression variable idx=12 avec p-value=0.8425156178884275\n",
      "Suppression variable idx=32 avec p-value=0.8152850361311793\n",
      "Suppression variable idx=35 avec p-value=0.8763565531619564\n",
      "Suppression variable idx=36 avec p-value=0.8987591723250102\n",
      "Suppression variable idx=8 avec p-value=0.7527384438206777\n",
      "Suppression variable idx=20 avec p-value=0.6749435111378066\n",
      "Suppression variable idx=33 avec p-value=0.6534993147593869\n",
      "Suppression variable idx=27 avec p-value=0.7741444263628234\n",
      "Suppression variable idx=19 avec p-value=0.5844077682144027\n",
      "Suppression variable idx=14 avec p-value=0.4996760834349022\n",
      "Suppression variable idx=28 avec p-value=0.42195835429374084\n",
      "Suppression variable idx=31 avec p-value=0.3617378816879484\n",
      "Suppression variable idx=24 avec p-value=0.2740925078831174\n",
      "Suppression variable idx=18 avec p-value=0.3248853648635103\n",
      "Suppression variable idx=21 avec p-value=0.37028017653919076\n",
      "Suppression variable idx=29 avec p-value=0.37028017653918965\n",
      "Suppression variable idx=9 avec p-value=0.33827867301293046\n",
      "Suppression variable idx=11 avec p-value=0.221966320330287\n",
      "Suppression variable idx=2 avec p-value=0.12664299069441834\n",
      "Suppression variable idx=7 avec p-value=0.23408158122164624\n",
      "Suppression variable idx=22 avec p-value=0.09786338108538206\n",
      "Suppression variable idx=10 avec p-value=0.06842127585556694\n",
      "Suppression variable idx=3 avec p-value=0.2214519537130677\n",
      "Suppression variable idx=15 avec p-value=0.10717987125462407\n",
      "Suppression variable idx=26 avec p-value=0.10487403439059761\n",
      "Suppression variable idx=25 avec p-value=0.05783687524822941\n",
      "Suppression variable idx=5 avec p-value=0.05830656018347919\n",
      "Suppression variable idx=17 avec p-value=0.12197013184682981\n",
      "Suppression variable idx=1 avec p-value=0.10320356531836014\n",
      "\n",
      "Variables retenues après backward elimination : [0, 13, 23, 34]\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                      y   R-squared (uncentered):                   0.815\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.795\n",
      "Method:                 Least Squares   F-statistic:                              40.76\n",
      "Date:                Wed, 30 Jul 2025   Prob (F-statistic):                    4.44e-13\n",
      "Time:                        18:44:15   Log-Likelihood:                         -672.50\n",
      "No. Observations:                  41   AIC:                                      1353.\n",
      "Df Residuals:                      37   BIC:                                      1360.\n",
      "Df Model:                           4                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "x1          1.798e+06   5.32e+05      3.377      0.002    7.19e+05    2.88e+06\n",
      "x2          7.068e+06   3.39e+06      2.087      0.044    2.05e+05    1.39e+07\n",
      "x3          8.807e+06   2.48e+06      3.556      0.001    3.79e+06    1.38e+07\n",
      "x4          6.062e+06   5.72e+05     10.596      0.000     4.9e+06    7.22e+06\n",
      "==============================================================================\n",
      "Omnibus:                        4.848   Durbin-Watson:                   1.575\n",
      "Prob(Omnibus):                  0.089   Jarque-Bera (JB):                3.067\n",
      "Skew:                           0.483   Prob(JB):                        0.216\n",
      "Kurtosis:                       2.072   Cond. No.                         6.42\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\n",
      "Nombre de features sélectionnées par RFE : 20\n",
      "RFE + Ridge - R² sur test : 0.2582\n",
      "RFE + Ridge - RMSE sur test : 2849951.56\n",
      "Indices des features retenues par RFE : [ 0  1  5  6  7 10 11 13 14 17 19 22 23 24 25 26 27 28 32 36]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "import statsmodels.api as sm\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "df = pd.read_csv(\"logement_cleaned.csv\")\n",
    "\n",
    "bool_cols = [col for col in df.columns if df[col].dtype == \"bool\"]\n",
    "for col in bool_cols:\n",
    "    df[col] = df[col].astype(int)\n",
    "\n",
    "num_cols = [\"superficie\", \"surface_terrain\", \"nombre_chambres\", \"nombre_salles_eau\"] + bool_cols\n",
    "cat_cols = [\"quartier\", \"douche_wc\", \"etat_general\", \"type_d_acces\", \"type_logement\"]\n",
    "\n",
    "X = df.drop(columns=[\"loyer_mensuel\"])\n",
    "y = df[\"loyer_mensuel\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "num_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "cat_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)) \n",
    "])\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", num_transformer, num_cols),\n",
    "    (\"cat\", cat_transformer, cat_cols)\n",
    "])\n",
    "\n",
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "\n",
    "X_train_sm = sm.add_constant(X_train_preprocessed)\n",
    "\n",
    "cols = list(range(X_train_sm.shape[1]))\n",
    "\n",
    "def backward_elimination(X, y, cols, sl=0.05):\n",
    "    \"\"\"\n",
    "    Backward elimination basée sur p-values.\n",
    "    X : array numpy (avec constante)\n",
    "    y : target\n",
    "    cols : liste indices des colonnes actuellement retenues\n",
    "    sl : seuil de significativité\n",
    "    \"\"\"\n",
    "    while True:\n",
    "        X_opt = X[:, cols]\n",
    "        model = sm.OLS(y, X_opt).fit()\n",
    "        pvalues = model.pvalues\n",
    "        max_pval = max(pvalues)\n",
    "        if max_pval > sl:\n",
    "            max_pval_index = pvalues.argmax()\n",
    "            print(f\"Suppression variable idx={cols[max_pval_index]} avec p-value={max_pval}\")\n",
    "            cols.pop(max_pval_index)\n",
    "        else:\n",
    "            break\n",
    "    return cols, model\n",
    "\n",
    "cols_selected, model_final = backward_elimination(X_train_sm, y_train.values, cols)\n",
    "\n",
    "print(\"\\nVariables retenues après backward elimination :\", cols_selected)\n",
    "print(model_final.summary())\n",
    "\n",
    "X_train_transformed = preprocessor.transform(X_train)\n",
    "X_test_transformed = preprocessor.transform(X_test)\n",
    "\n",
    "ridge = Ridge(alpha=1.0)\n",
    "n_features_to_select = 20  \n",
    "\n",
    "selector = RFE(estimator=ridge, n_features_to_select=n_features_to_select, step=1)\n",
    "selector = selector.fit(X_train_transformed, y_train)\n",
    "\n",
    "print(f\"\\nNombre de features sélectionnées par RFE : {sum(selector.support_)}\")\n",
    "\n",
    "X_train_rfe = selector.transform(X_train_transformed)\n",
    "X_test_rfe = selector.transform(X_test_transformed)\n",
    "\n",
    "ridge.fit(X_train_rfe, y_train)\n",
    "y_pred_rfe = ridge.predict(X_test_rfe)\n",
    "\n",
    "r2 = r2_score(y_test, y_pred_rfe)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_rfe))\n",
    "\n",
    "print(f\"RFE + Ridge - R² sur test : {r2:.4f}\")\n",
    "print(f\"RFE + Ridge - RMSE sur test : {rmse:.2f}\")\n",
    "\n",
    "print(\"Indices des features retenues par RFE :\", np.where(selector.support_)[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c821bd",
   "metadata": {},
   "source": [
    "\n",
    "# TP : Prédire le prix de location de logements à Antananarivo avec une régression linéaire multiple\n",
    "\n",
    "## 🎯 Objectifs pédagogiques\n",
    "\n",
    "- Appliquer un pipeline de prétraitement complet sur un jeu de données semi-structuré.\n",
    "- Gérer les variables qualitatives, les valeurs manquantes, la multicolinéarité et la scalabilité.\n",
    "- Construire, tester et évaluer un modèle de régression linéaire multiple.\n",
    "- Déployer le modèle dans une application Python Streamlit avec interface utilisateur.\n",
    "\n",
    "## 🗂️ Jeu de données\n",
    "\n",
    "Le jeu de données doit être collecté ou scrappé dans les pages comme Facebook. Il doit comporter les colonnes suivantes :\n",
    "\n",
    "- `quartier` (catégorielle)\n",
    "- `superficie` (numérique)\n",
    "- `nombre_chambres` (numérique)\n",
    "- `douche_wc`(interieur ou exterieur)\n",
    "- `type_d_acces` (sans, moto, voiture, voiture_avec_par_parking)\n",
    "- `meublé` (booléen:  oui ou non)\n",
    "- `état_général` (catégorielle : bon, moyen, mauvais)\n",
    "- `loyer_mensuel` (target)\n",
    "\n",
    "## 🧪 Étapes du TP\n",
    "\n",
    "### 📌 Partie 1 : Préparation des données\n",
    "- Lecture du dataset brut\n",
    "- Gestion des valeurs manquantes\n",
    "- Encodage des variables catégorielles\n",
    "- Création de variables dérivées\n",
    "- Détection et suppression des variables fortement corrélées\n",
    "- Standardisation et normalisation\n",
    "\n",
    "### 📌 Partie 2 : Modélisation\n",
    "\n",
    "- Séparation train/test\n",
    "- Implémentation de la régression linéaire multiple\n",
    "- Évaluation : R², RMSE\n",
    "- Vérification des hypothèses d'élligibilité de la régression linéaire multiple (surtout sur les erreurs)\n",
    "\n",
    "### 📌 Partie 3 : Optimisation du modèle\n",
    "\n",
    "- Sélection de variables : backward elimination, RFE (à documenter)\n",
    "\n",
    "### 📌 Partie 4 : Déploiement d’une application Streamlit\n",
    "\n",
    "- Interface de saisie utilisateur\n",
    "- Affichage du loyer prédit\n",
    "- Visualisation des poids des variables\n",
    "- Affichage sur la carte interactive\n",
    "\n",
    "## 🧭 Carte interactive (option avancée)\n",
    "\n",
    "Utiliser `streamlit-folium` pour permettre à l’utilisateur de cliquer sur une carte et de récupérer les coordonnées GPS. À partir de ces coordonnées, déterminer automatiquement le quartier en utilisant un fichier GeoJSON ou un système de polygones avec `geopandas`.\n",
    "\n",
    "## 🔧 Technologies à utiliser\n",
    "\n",
    "- `pandas`, `numpy`, `scikit-learn`, `matplotlib`, `seaborn`, `joblib`\n",
    "- `streamlit`, `folium`, `streamlit-folium`\n",
    "- Optionnel : `geopandas`, `shapely`\n",
    "\n",
    "## 💡 Bonus\n",
    "\n",
    "- Carte interactive avec folium\n",
    "- Simuler des données additionnelles (pollution, sécurité)\n",
    "- Tri automatique des caractéristiques influentes\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
